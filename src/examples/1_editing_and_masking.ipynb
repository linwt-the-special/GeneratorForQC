{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a855f1-55dd-482e-94f2-9ad02804be4d",
   "metadata": {},
   "source": [
    "# Editing and masking of circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e2465-49d8-46b8-b046-6ae1becfb268",
   "metadata": {},
   "source": [
    "In this notebook we show editing and masking of circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde494e-9091-41a4-a601-bbcf9712c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator.imports import *\n",
    "from generator.pipeline.diffusion_pipeline import DiffusionPipeline\n",
    "from generator.inference.infer_srv import convert_tensors_to_srvs, schmidt_rank_vector\n",
    "import generator.platform.qcircuit_dataset_construction as data_const\n",
    "from generator.platform.simulation.qcircuit_sim import instruction_name_to_gate\n",
    "import generator.util as util\n",
    "from QuICT.simulation.density_matrix import DensityMatrixSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029be4f3-0d9a-4d0a-93d9-2338fda7a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = util.infer_torch_device()  # use cuda if we can\n",
    "util.MemoryCleaner.purge_mem()      # clean existing memory alloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a3020-247c-4ac0-aaf1-ee5c371b5f06",
   "metadata": {},
   "source": [
    "## Setup and load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ae430-46f2-4099-ac8f-f422a4ddc1dc",
   "metadata": {},
   "source": [
    "Load the pre-trained model directly from [Hugging Face: Floki00/qc_srv_3to8qubit](https://huggingface.co/Floki00/qc_srv_3to8qubit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d60c23-9514-4432-bc82-622c088fced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DiffusionPipeline.from_pretrained(\"Floki00/qc_srv_3to8qubit\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d3e29-f121-4c61-95bc-bfd7960a4870",
   "metadata": {},
   "source": [
    "Set 20 sample steps and use rescaled guidance-formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96702fba-5a10-44e6-bef9-634d9e41a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.guidance_sample_mode = \"rescaled\"\n",
    "pipeline.scheduler.set_timesteps(40) \n",
    "g = 7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65acff8f-8486-42c9-8e78-b44f31de568b",
   "metadata": {},
   "source": [
    "## 1. Editing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e6870-b895-4acd-96e3-135a96979d9e",
   "metadata": {},
   "source": [
    "Sample a random circuit with desired parameters as the circuit we want to edit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ee84d-3c02-4d9c-ae76-b6290efaec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "srv_init       = [1, 1, 1, 2, 2]   # psi_0 state\n",
    "desired_length = 5                 # 5 gates initially placed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94961d3-b053-4064-8845-28320927e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_pool = [instruction_name_to_gate(gate) for gate in pipeline.gate_pool]\n",
    "init_qc   = data_const.get_specific_rnd_srv_circuit(srv_init, desired_length, gate_pool)\n",
    "simulator = DensityMatrixSimulator(\n",
    "    device=\"CPU\",\n",
    "    precision=\"double\"\n",
    ") \n",
    "\n",
    "print(\"SRV is\", schmidt_rank_vector(simulator.run(init_qc)))\n",
    "init_qc.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf40c0-6535-4c2c-b62e-7e8ea6c37263",
   "metadata": {},
   "source": [
    "The editing taks is analogous to image editing, we do img2img with conditioning and copy non-edit areas at every time step. Also called `latent_filling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e2d7d-8dcb-4c6a-82d3-c1525ae5f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edited_circuits(pipeline, samples, qc, prompt, new_length, num_of_qubits, system_size, t_start_index):\n",
    "    #-------------------------------------------\n",
    "    # set mask - appending mask!\n",
    "    old_length = len(qc.data)\n",
    "\n",
    "    qubit_mask = torch.ones((system_size, new_length), device=device)\n",
    "    qubit_mask[:, :old_length] = 0\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    # prepare and encode\n",
    " \n",
    "    gate_classes = data_const.gate_pool_to_gate_classes(gate_pool)\n",
    "   \n",
    "    emb_org_image = data_const.encode_circuit(qc, system_size, gate_classes, new_length).unsqueeze(0).to(device)\n",
    "    emb_org_image = pipeline.model.embedd_clrs(emb_org_image)\n",
    "\n",
    "    emb_org_images = emb_org_image.repeat(samples, *[1]*(emb_org_image.dim()-1))\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    # prep condition\n",
    "    \n",
    "    c = pipeline.text_encoder.tokenize_and_push_to_device(str(prompt))\n",
    "    c = c.repeat(samples, *[1]*(c.dim()-1))\n",
    "\n",
    "    #-------------------------------------------\n",
    "    # latent fill\n",
    "    out_tensor = pipeline.latent_filling(emb_org_images, qubit_mask, c=c, g=g, no_bar=False, t_start_index=t_start_index)\n",
    "    out_tensor = pipeline.model.invert_clr(out_tensor)\n",
    "    out_tensor = out_tensor[:, :num_of_qubits]\n",
    "    out_tensor = torch.unique(out_tensor, dim=0) # we only are interested in unique circuits\n",
    "   \n",
    "    qc_list, error_cnt, srv_list = convert_tensors_to_srvs(out_tensor, pipeline.gate_pool, place_barrier=True)\n",
    "\n",
    "    return qc_list, srv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b99db-e321-4b03-a47f-1ce753495eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples    = 16   # how many circuits we sample\n",
    "new_length = 16   # how many gates the model can place \n",
    "\n",
    "srv_target    = [2, 2, 2, 2, 2]  # desired target SRV\n",
    "\n",
    "num_of_qubits = len(srv_target)\n",
    "t_start_index = t_start_index = int(0.05 * pipeline.scheduler.timesteps.shape[0])  # time step index at which we start denoising\n",
    "\n",
    "prompt = f\"Generate SRV: {srv_target}\"  # model was trained with this phrase\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b9d6a-7611-4664-b9d7-424d068f974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns only distinct circuits\n",
    "edited_qc, srv_list = create_edited_circuits(pipeline, samples, init_qc, prompt, new_length, num_of_qubits, num_of_qubits, t_start_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5bfeee-4693-4110-9500-fb03c06ac2f3",
   "metadata": {},
   "source": [
    "Pick only correct ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313bab5f-8c99-43e4-9ae3-7305a5ac4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_edited_qc = []\n",
    "for qc,srv in zip(edited_qc, srv_list):\n",
    "    if srv==srv_target: correct_edited_qc.append(qc)\n",
    "print(f\"We found {len(correct_edited_qc)} correct distinct solutions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd981467-9c73-43fa-8dec-3fa4aafc50d3",
   "metadata": {},
   "source": [
    "Compare: initial circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f7aad-d1d6-4cf9-bd9e-8fd1908e687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_qc.draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4189622c-47c1-4d16-b153-b3bb55d25f63",
   "metadata": {},
   "source": [
    "v.s. edited:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b383e40-e2bc-4166-a363-45a8cf6e2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = DensityMatrixSimulator(\n",
    "    device=\"CPU\",\n",
    "    precision=\"double\"\n",
    ") \n",
    "print(\"SRV is\", schmidt_rank_vector(simulator.run(correct_edited_qc[0])))\n",
    "correct_edited_qc[0].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2bf73-8cab-4248-88b2-810b58cfc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize=(18,5), constrained_layout=True)\n",
    "for qc,ax in zip(correct_edited_qc, axs.flatten()): \n",
    "    qc.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c30bcc-1967-4c78-a6df-61f831838535",
   "metadata": {},
   "source": [
    "## 2. Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda0d38-a56b-4f3f-b8cd-61a21604bd57",
   "metadata": {},
   "source": [
    "First we set a desired mask, i.e. a specific layout of a quantum processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b5feb-6eeb-4cc1-94f4-85dc401cc464",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_gates     = 16\n",
    "num_of_qubits = 5\n",
    "\n",
    "d = 3\n",
    "#------\n",
    "def con_set(q1, q2, x, d): \n",
    "    qubit_mask[q1, x:x+d] = 1\n",
    "    qubit_mask[q2, x:x+d] = 1\n",
    "    return x+d\n",
    "\n",
    "#------\n",
    "x = 0\n",
    "\n",
    "qubit_mask = torch.zeros((num_of_qubits, max_gates), device=device) # mask: ones are getting filled, zeros are fixed !\n",
    "x = con_set(0, 1, x, d)\n",
    "x = con_set(1, 2, x, d)\n",
    "x = con_set(1, 3, x, d)\n",
    "x = con_set(3, 4, x, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5927f5d5-9e0d-4d85-b4a3-a37b2ad9136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mask():\n",
    "    fig = plt.figure(figsize=(3.7,2), constrained_layout=True)\n",
    "    plt.imshow(qubit_mask.cpu(), cmap=\"Greens\")\n",
    "    plt.xticks(range(0, qubit_mask.shape[1], 2),fontsize=9)\n",
    "    plt.yticks(range(num_of_qubits), fontsize=9)\n",
    "    plt.xlabel(\"Gate sequence / time\", fontsize=12)\n",
    "    plt.ylabel(\"Qubits\", fontsize=12)\n",
    "    plt.show()\n",
    "plot_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f4eca-1486-45f2-86be-b3f7be87591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_org_images(pipeline, samples, system_size, max_gates, target_num_gates, target_num_bits, qubit_mask):\n",
    "    org_image = torch.zeros((1, system_size, max_gates), device=device, dtype=torch.int32) \n",
    "    \n",
    "    padd_tok = len(pipeline.gate_pool) + 1\n",
    "    padd_pos = (torch.ceil(torch.tensor(target_num_gates) / 4) * 4).to(torch.int32)\n",
    "    org_image[:,                :, padd_pos:] = padd_tok\n",
    "    org_image[:, target_num_bits:,          ] = padd_tok\n",
    "\n",
    "    emb_org_image  = pipeline.model.embedd_clrs(org_image)\n",
    "    emb_org_images = emb_org_image.repeat(samples, *[1]*(emb_org_image.dim()-1))\n",
    "    \n",
    "    return emb_org_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732510e-4888-4a2f-88b6-a579e35ef721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pattern_SRV(pipeline, prompt, samples, system_size, num_of_qubits, max_gates, qubit_mask, t_start_index=0, target_num_gates=None, target_num_bits=None): \n",
    "\n",
    "    if not exists(target_num_gates):\n",
    "        target_num_gates = max_gates\n",
    "\n",
    "    if not exists(target_num_bits):\n",
    "        target_num_bits = num_of_qubits\n",
    "    \n",
    "    emb_org_images = get_emb_org_images(pipeline, samples, system_size, max_gates, target_num_gates, target_num_bits, qubit_mask)\n",
    "\n",
    "    #----------------\n",
    "    # prep condition\n",
    "\n",
    "    c = pipeline.text_encoder.tokenize_and_push_to_device(str(prompt))\n",
    "    c = c.repeat(samples, *[1]*(c.dim()-1))\n",
    "\n",
    "    #----------------\n",
    "    # latent fill\n",
    "    \n",
    "    out_tensor = pipeline.latent_filling(emb_org_images, qubit_mask, c=c, g=g, no_bar=False, t_start_index=t_start_index)\n",
    "    out_tensor = pipeline.model.invert_clr(out_tensor)\n",
    "    out_tensor = out_tensor[:, :num_of_qubits]\n",
    "    out_tensor = torch.unique(out_tensor, dim=0)\n",
    "     \n",
    "    qc_list, error_cnt, srv_list = convert_tensors_to_srvs(out_tensor, pipeline.gate_pool, place_barrier=True)\n",
    "\n",
    "    return qc_list, srv_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3bb0b7-6409-43f1-a513-bd09676b3a98",
   "metadata": {},
   "source": [
    "Now generate circuits corresponding to the mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b8784-0132-49a4-ab17-9169960cc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples    = 512              # how many circuits we sample\n",
    "srv_target = [2, 1, 2, 2, 2]  # desired target SRV\n",
    "\n",
    "assert len(srv_target)==qubit_mask.shape[0]\n",
    "\n",
    "prompt = f\"Generate SRV: {srv_target}\"  # model was trained with this phrase\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24cfdeb-825f-43c0-9efc-a3dc1819b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_list, srv_list = generate_pattern_SRV(pipeline, prompt, samples, num_of_qubits, num_of_qubits, max_gates, qubit_mask, t_start_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad4beb7-97ea-4293-9abc-bc1472f2f7f0",
   "metadata": {},
   "source": [
    "Pick only correct ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83294a34-a93f-4597-b5ad-65b88e7f332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_qc = []\n",
    "for qc,srv in zip(qc_list, srv_list):\n",
    "    if srv==srv_target: correct_qc.append(qc)\n",
    "print(f\"We found {len(correct_qc)} correct distinct solutions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda61abc-5fd2-48df-b7b6-11c0d98f2450",
   "metadata": {},
   "source": [
    "Let's plot them. Mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b89db4-8163-4651-b049-033d9984f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cbbef9-2fa7-4292-b6a5-ad10b11421f1",
   "metadata": {},
   "source": [
    "v.s. solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf638ca-0513-4d82-8fa3-cac6deaaeb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = DensityMatrixSimulator(\n",
    "    device=\"CPU\",\n",
    "    precision=\"double\"\n",
    ") \n",
    "print(\"SRV is\", schmidt_rank_vector(simulator.run(correct_qc[0])))\n",
    "correct_qc[0].draw(\"mpl\", plot_barriers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f5ff7-0699-4229-94e1-ff3e065bd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, min(len(correct_qc), 4), figsize=(18,5), constrained_layout=True)\n",
    "for qc,ax in zip(correct_qc, axs.flatten()): \n",
    "    qc.draw(\"mpl\", plot_barriers=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684de45e-432d-4bee-8a88-dac2134f4b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48bb0e5-b8e4-4940-b7cd-4efd81c438e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import genQC\n",
    "print(\"genQC Version\", genQC.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
